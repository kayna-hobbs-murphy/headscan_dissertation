---
title: "MANOVA assumptions"
output: html_document
date: "2022-08-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(tidyverse)
library(readxl)
library(officer)
library(flextable)
library(extrafont)
library(writexl)
library(rstatix)
```




FOR EACH MEASURE: 

To check normality:
QQ plot (A Q-Q plot or Quantile-Quantile plot is a common graphical way to check data for non-normality. Quantile is another term for percentile. A Q-Q plot is a plot of the quantiles of a data set versus the quantiles of a reference theoretical distribution. This plot is used to assess normality of residuals. Curvature and outliers indicate problems. Note: The QQ plot is not useful until variance is
approximately equal.)

shapiro.test with p value greater than 0.05 (Histograms and QQ plots are usually more informative than the tests, because small sample sizes generally “pass” the test (high p-value, no evidence against normality), and large sample sizes generally “fail” (small p-value, evidence against normality).)

 
To check for outliers:

Standardized (or studentized) residuals are residuals that have been
“standardized” by dividing each residual by it’s SE.
• They have approximately a t-distribution, which is approximately
normal for moderate sample sizes, so we expect that about 95% of the
standardized residuals will be between -2 and +2. Values greater in
absolute value than 3.5 are usually considered outliers.
• In R, standardized residuals can be found using
rstandard(ModelObject).


To check homogeneity of covariances/equal variance:

Box's test (homegeneity of variance-covariance matrices)

Levene’s test of equality of variances (homogeneity of variances)

Plot of residuals vs fitted values (equal scatter; This is the primary diagnostic plot for assessing linearity and constant
variance. Curvature, unequal variance (megaphone) or outliers indicate problems.)



To check linear response:

Plot of resids vs fitted values (should not show a trend)

Look to pages 20-end 512 MultReg1



For y variables: You should have an adequate sample size. Although the larger your sample size, the better, at a bare minimum, there needs to be as many cases (e.g., particpants) in each cell of the design as there are number of dependent variables. 12 dependent variables


For MANOVA, the dependent variables should be somewhat correlated. 



STEPS: 
Power analysis to find sample size - 278
NAs shouldn't be over 20%
Find outliers & remove
Double check correlations
check assumptions 
run manova
run anovas

```{r table-function}
#times new roman tables
my_ft_theme <- function(ft, ...) {
  # Remove vertical cell padding
  ft <- padding(ft, padding.top = 0, padding.bottom = 0, part = "all")
  
  # Change font to TNR 11
  ft <- font(ft, fontname = "Times New Roman", part = "all")
  ft <- fontsize(ft, part = "all", size = 12)
  ft
}
```

```{r}
#remove identifiers and demographic data

headscan_full<-read_excel("C:\\Users\\19177\\OneDrive - Colostate\\Desktop\\Dissertation\\headscan_dissertation\\headscan_full.xlsx")

headscan_full$AA_C <- headscan_full$AA_C *10
headscan_full$BGl_C <- headscan_full$BGl_C * 10
headscan_full$BiW_C <- headscan_full$BiW_C *10
headscan_full$BiW_L <- headscan_full$BiW_L *10
headscan_full$ChCh_C <- headscan_full$ChCh_C *10
headscan_full$GoSub_C <- headscan_full$GoSub_C *10
headscan_full$NRB_L <- headscan_full$NRB_L *10
headscan_full$ProA_L <- headscan_full$ProA_L *10
headscan_full$ProA_C <- headscan_full$ProA_C *10
headscan_full$ProS_C <- headscan_full$ProS_C *10
headscan_full$ProS_L <- headscan_full$ProS_L *10
headscan_full$SelP_C <- headscan_full$SelP_C *10
headscan_full$SelP_L <- headscan_full$SelP_L *10
headscan_full$SelDH_C <- headscan_full$SelDH_C *10
headscan_full$SelM_L <- headscan_full$SelM_L *10
headscan_full$SnasM_C <- headscan_full$SnasM_C *10
headscan_full$SmanM_C <- headscan_full$SmanM_C *10
headscan_full$SmanM_L <- headscan_full$SmanM_L *10
headscan_full$SnasM_L <- headscan_full$SnasM_L *10
headscan_full$TrHO_C <- headscan_full$TrHO_C *10
headscan_full$TrEJ_C <- headscan_full$TrEJ_C *10
headscan_full$TrGo_C <- headscan_full$TrGo_C *10
headscan_full$TrSel_C <- headscan_full$TrSel_C *10
headscan_full$TrSman_C <- headscan_full$TrSman_C *10
headscan_full$TrSnas_C <- headscan_full$TrSnas_C *10
headscan_full$TrTr_C <- headscan_full$TrTr_C *10
headscan_full$TrTr_L <- headscan_full$TrTr_L *10

headscan_full$gender <- as.factor(headscan_full$gender)
headscan_full$race_eth <- as.factor(headscan_full$race_eth)
headscan_full$age_group <- as.factor(headscan_full$age_group)

str(headscan_full)
```

```{r}
SA3_data <- headscan_full[c(1,2,4,5,7,8,12,14,16,17,25,27,28,31,32,33)]
```


```{r}
SA3_NAsums <- colSums(is.na(SA3_data))

SA3_NAprops <- colMeans(is.na(SA3_data))

SA3_NAprops1 <- as.data.frame(SA3_NAprops)
SA3_NAprops1 <- rownames_to_column(SA3_NAprops1, "var_name")
SA3_NAprops1 <- SA3_NAprops1 %>% slice(-c(1, 29:33))

SA3_NAsums1 <- as.data.frame(SA3_NAsums)
SA3_NAsums1 <- rownames_to_column(SA3_NAsums1, "var_name")
SA3_NAsums1 <- SA3_NAsums1 %>% slice(-c(1, 29:33))

SA3_NAs <- inner_join(SA3_NAprops1, SA3_NAsums1, by = "var_name", desc)

SA3_NAs$SA3_NAprops<- round(SA3_NAs$SA3_NAprops, digits=4)

SA3_NAs$var_name <- fct_reorder(SA3_NAs$var_name, SA3_NAs$SA3_NAsums, .desc=TRUE)

str(SA3_NAs$SA3_name)

#Size 12 Table TNR
flextable(SA3_NAs) %>%
  my_ft_theme()%>% 
  bold(part = "header") %>% 
  set_caption("NA values for each MANOVA Variable") %>% 
  autofit() %>% 
  set_header_labels(values = list(var_name = "Variable",
                                  SA3_NAprops = "Proportion of NA values",
                                  SA3_NAsums = "Count of NA values"))
```





```{r}
SA3_data1 <- SA3_data

#race/eth
SA3_data1$race_eth <-  
  recode_factor(SA3_data1$race_eth, 'AIAN'= "Other",
                'NHOPI' = "Other",
                'PTNS' = "Other")

#gender
SA3_data1$gender <-  
  recode_factor(SA3_data1$gender, 'Non-binary or Other'= "Other",
                'Prefer not to say' = "Other")

SA3_data1$gender[is.na(SA3_data1$gender)]="Other"


summary(SA3_data1)
```




#Dr. Erin Buchanan from Missouri State
If there were missing data categories over 20%, I could replace the data? According to manova-9 notes

Otherwise, it seems like I have to delete the missing values. I did this for PCA as well. 


```{r}

SA3_data2 <- SA3_data1 %>% drop_na()

sum(is.na(SA3_data1))

2016-1710
```
#306 observations were deleted when we dropped NAs. That is not bad considering there are 892 missing values



Next, identify univariate outliers


```{r}
AA_C_out <- SA3_data2 %>% 
  identify_outliers(AA_C)

AA_C_out$testgroup <- "overall"

AA_C_out <- AA_C_out[c(1,2,18,19)]

AA_C_out <- AA_C_out[AA_C_out$is.extreme == "TRUE",]

AA_C_out <- AA_C_out %>% 
  mutate("TRUE"=TRUE) %>% 
  pivot_wider(names_from = testgroup, values_from = "TRUE", values_fill=FALSE)



AA_C_out1 <- SA3_data2 %>% 
  group_by(race_eth) %>% 
  identify_outliers(AA_C)

AA_C_out1$testgroup <- "race_eth"

AA_C_out1 <- AA_C_out1[c(1,2,18,19)]



AA_C_out2 <- SA3_data2 %>% 
  group_by(gender) %>% 
  identify_outliers(AA_C)

AA_C_out2$testgroup <- "gender"


AA_C_out3 <- SA3_data2 %>% 
  group_by(age_group) %>% 
  identify_outliers(AA_C)

AA_C_out3$testgroup <- "age_group"


#AA_C_extreme <- rbind(AA_C_out, AA_C_out1, AA_C_out2, AA_C_out3)

#AA_C_extreme <- AA_C_extreme[c(1,2,18,19)]


#AA_C_extreme1 <- AA_C_extreme[AA_C_extreme$is.extreme == "TRUE",]

#AA_C_extreme1 <- AA_C_extreme1 %>% 
  #mutate("TRUE"=TRUE) %>% 
  #pivot_wider(names_from = testgroup, values_from = "TRUE", values_fill=FALSE)



summary(AA_C_extreme)
tibble(AA_C_extreme1)


```

#Size 12 Table TNR
flextable(AA_Csumstats) %>%
  my_ft_theme()%>% 
  bold(part = "header") %>% 
  set_caption("Alare to Alare Contour SumStats") 
#%>% set_header_labels(values = list(AA_C = "Alare/AlareCont"))

#Autofit Width Table TNR
flextable(AA_Csumstats) %>%
  my_ft_theme()%>% 
  bold(part = "header") %>% 
  set_caption("Alare to Alare Contour SumStats") %>% 
  fit_to_width(7.5) 
#%>% set_header_labels(values = list(AA_C = "Alare/AlareCont"))

n_occur_AA_C <- data.frame(table(AA_C_extreme$ID))
n_occur_AA_C[n_occur_AA_C$Freq > 1,]
AA_C_extreme[AA_C_extreme$ID %in% n_occur_AA_C$Var1[n_occur_AA_C$Freq > 1],]

```{r}
BiW_C_out <- SA3_data2 %>% 
  identify_outliers(BiW_C)

BiW_C_out$testgroup <- "overall"


BiW_C_out1 <- SA3_data2 %>% 
  group_by(race_eth) %>% 
  identify_outliers(BiW_C)

BiW_C_out1$testgroup <- "race_eth"


BiW_C_out2 <- SA3_data2 %>% 
  group_by(gender) %>% 
  identify_outliers(BiW_C)

BiW_C_out2$testgroup <- "gender"


BiW_C_out3 <- SA3_data2 %>% 
  group_by(age_group) %>% 
  identify_outliers(BiW_C)

BiW_C_out3$testgroup <- "age_group"


BiW_C_extreme <- rbind(BiW_C_out, BiW_C_out1, BiW_C_out2, BiW_C_out3)

BiW_C_extreme <- BiW_C_extreme[c(1,2,18,19)]


BiW_C_extreme1 <- BiW_C_extreme[BiW_C_extreme$is.extreme == "TRUE",]

BiW_C_extreme1 <- BiW_C_extreme1 %>% 
  mutate("TRUE"=TRUE) %>% 
  pivot_wider(names_from = testgroup, values_from = "TRUE", values_fill=FALSE)


summary(BiW_C_extreme)
tibble(BiW_C_extreme1)


```

```{r}
BiW_L_out <- SA3_data2 %>% 
  identify_outliers(BiW_L)

BiW_L_out$testgroup <- "overall"


BiW_L_out1 <- SA3_data2 %>% 
  group_by(race_eth) %>% 
  identify_outliers(BiW_L)

BiW_L_out1$testgroup <- "race_eth"


BiW_L_out2 <- SA3_data2 %>% 
  group_by(gender) %>% 
  identify_outliers(BiW_L)

BiW_L_out2$testgroup <- "gender"


BiW_L_out3 <- SA3_data2 %>% 
  group_by(age_group) %>% 
  identify_outliers(BiW_L)

BiW_L_out3$testgroup <- "age_group"


BiW_L_extreme <- rbind(BiW_L_out, BiW_L_out1, BiW_L_out2, BiW_L_out3)

BiW_L_extreme <- BiW_L_extreme[c(1,2,18,19)]


BiW_L_extreme1 <- BiW_L_extreme[BiW_L_extreme$is.extreme == "TRUE",]

BiW_L_extreme1 <- BiW_L_extreme1 %>% 
  mutate("TRUE"=TRUE) %>% 
  pivot_wider(names_from = testgroup, values_from = "TRUE", values_fill=FALSE)


summary(BiW_L_extreme)
tibble(BiW_L_extreme1)
```
